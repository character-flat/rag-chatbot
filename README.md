
# ğŸ§  RAG Chatbot (FOSS-Only Edition)

This is a lightweight, fully open-source Retrieval-Augmented Generation (RAG) chatbot that answers questions from long documents (e.g. PDFs, scraped websites, etc.). It uses:

- âœ… Open-source embedding models (`sentence-transformers`)
- âœ… FAISS for vector similarity search
- âœ… `google/flan-t5-small` for answer generation
- âœ… Local preprocessing with chunking and cleaning
- âœ… Gradio frontend (optional)

---

## ğŸ§© Architecture

```

User Question
â”‚
â–¼
\[ Embedding Model ]
â”‚
â–¼
\[ FAISS Vector DB ] â† Preprocessed Chunks
â”‚
Top-k Most Similar Chunks
â”‚
â–¼
\[ FLAN-T5-Small ]
â”‚
â–¼
Generated Answer

```

---

## ğŸ“š Data Source

The input data used in this project comes from **insurance-related PDFs and scraped coverage summaries**. These documents contain:

- Summaries of benefits and coverage
- Tables for deductibles, co-pays, and network benefits
- Legal and regulatory disclaimers

These were cleaned and converted to plain text in `data/final_dataset.txt`.

> ğŸ“Œ Note: The quality of responses depends heavily on how relevant and clean this source data is. Garbage in, garbage out.

---

## âœ… Advantages

- **Fully Open-Source**: No APIs, no vendor lock-in.
- **Lightweight**: Runs on CPU or small GPU; suitable for local or Hugging Face Spaces deployment.
- **Customizable**: Easily change models, chunk sizes, or retrievers.
- **Privacy-Preserving**: No user data or documents leave your system.

---

## âŒ Limitations

- **Small Embedding Model**: Struggles with nuanced or domain-specific queries. Poor similarity scores can return irrelevant chunks.
- **Small Generator (FLAN-T5-Small)**: May hallucinate or give vague answers when context is weak.
- **No Reranker Yet**: Retrieval is purely based on cosine similarity; wrong top-k results degrade answer quality fast.
- **Bad Data = Bad Answers**: If the underlying dataset is off-topic, the bot cannot magically "understand" your question.

---

## ğŸ“‚ Folder Structure

```

.
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ final\_dataset.txt        # Raw input text (from insurance PDFs)
â”‚   â””â”€â”€ chunks/                  # Preprocessed chunks
â”œâ”€â”€ embed.py                     # Generates embeddings & builds FAISS index
â”œâ”€â”€ query.py                     # Answers user questions
â”œâ”€â”€ chunker.py                   # Splits large documents into overlapping chunks
â”œâ”€â”€ app.py                       # Gradio frontend (optional)
â””â”€â”€ README.md

````

---

## âš™ï¸ How to Run

### 1. Install dependencies
```bash
pip install -r requirements.txt
````

### 2. Chunk your document

```bash
python chunker.py
```

### 3. Embed & build vector index

```bash
python embed.py
```

### 4. Ask questions

```bash
python query.py
```

### 5. (Optional) Launch Gradio app

```bash
python app.py
```

---

## ğŸ§ª Tips for Better Performance

* Use **smaller chunk sizes** (e.g., 80â€“120 words) with overlap (e.g., 30 words).
* Filter out irrelevant content like glossaries, URLs, or legalese.
* Match your dataset to your domain (finance dataset for finance Qs, etc.).
* Try better embedding models like `bge-small-en-v1.5` or `e5-small-v2`.

---

## ğŸ› ï¸ Future Improvements

* Add a reranker model to improve retrieval relevance.
* Switch to `flan-t5-base` or `Mistral` for stronger generation.
* Add prompt templates with clearer instructions.
* Multi-document ingestion and metadata filtering.

---

## âœŠ License

MIT. Built with 100% open-source tools and vibes.

```


